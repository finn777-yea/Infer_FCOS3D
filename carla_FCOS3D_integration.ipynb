{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import signal\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import pickle\n",
    "from typing import Callable, Dict, Set, Tuple, Any\n",
    "\n",
    "from norospy import ROSFoxgloveClient\n",
    "\n",
    "from mmdet3d.apis import MonoDet3DInferencer\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(name)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client(\"localhost\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.load_world(\"Town03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_lib = world.get_blueprint_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_bp = bp_lib.filter(\"vehicle\")\n",
    "spawn_pts = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle = world.spawn_actor(random.choice(vehicle_bp), random.choice(spawn_pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn 50 vehicles randomly distributed throughout the map \n",
    "# for each spawn point, we choose a random vehicle from the blueprint library\n",
    "for i in range(0,50):\n",
    "    world.try_spawn_actor(random.choice(vehicle_bp), random.choice(spawn_pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vehicle in world.get_actors().filter('*vehicle*'):\n",
    "    vehicle.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ego_vehicle.get_transform()\n",
    "spectator.set_transform(carla.Transform(transform.location + carla.Location(z=2), carla.Rotation(yaw=90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_bp = None\n",
    "# TODO: set proper transformation to the cam\n",
    "cam_init_transform = carla.Transform(carla.Location(z=3))\n",
    "cam_bp = world.get_blueprint_library().find(\"sensor.camera.rgb\")\n",
    "cam = world.spawn_actor(cam_bp, cam_init_transform, attach_to=ego_vehicle)\n",
    "# cam.attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/ws/uqmfs/mmdetection3d/weights/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth\n",
      "05/30 16:38:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ws/uqmfs/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "config_path = \"/home/ws/uqmfs/mmdetection3d/configs/fcos3d/fcos3d_r101-caffe-dcn_fpn_head-gn_8xb2-1x_nus-mono3d_finetune.py\"\n",
    "checkpoint_path = \"/home/ws/uqmfs/mmdetection3d/weights/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth\"\n",
    "\n",
    "inferencer = MonoDet3DInferencer(config_path, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anotation(camera_matrix):\n",
    "    infos = {}\n",
    "    infos={\n",
    "        'data_list': [\n",
    "            {\n",
    "                'images': {\n",
    "                    'CAM2': {\n",
    "                        'img_path': None,\n",
    "                        'cam2img': camera_matrix,\n",
    "                        'lidar2img': np.array([]),\n",
    "                        'lidar2cam': np.array([]),\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    infos_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pkl')\n",
    "    pickle.dump(infos, infos_file)\n",
    "    infos_file.close()\n",
    "    return infos_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_inference(msg: Any, ts: int):\n",
    "    logging.info('Now here we are!')\n",
    "    # TODO: convert ros image msg to ndarray\n",
    "    img = ROSFoxgloveClient.parse_ros_image(msg)\n",
    "    # projection/camera matrix from ros topic\n",
    "    # P = np.array([400.00000000000006, 0, 400, 0, 0, 400.00000000000006, 300, 0, 0, 0, 1, 0], dtype=np.float64).reshape(3,4)\n",
    "    C = np.array([400.00000000000006, 0, 400, 0, 400.00000000000006, 300, 0, 0, 1], dtype=np.float64).reshape(3,3)\n",
    "    \n",
    "    # TODO: construct the pkl file based on the camera calibration\n",
    "    infos_file = get_anotation(camera_matrix=C)\n",
    "\n",
    "    input = dict(img=img, infos=infos_file.name)\n",
    "    results = inferencer(input, return_datasamples=False, return_vis=True, out_dir='/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded 124 message definitions\n",
      "INFO:root:Connecting ...\n",
      "INFO:root:Connected.\n",
      "INFO:root:Now here we are!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aee07bb5244a5a8aae6b0a9200e1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-777:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ws/uqmfs/miniconda3/envs/openmmlab/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ws/uqmfs/miniconda3/envs/openmmlab/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ws/uqmfs/miniconda3/envs/openmmlab/lib/python3.8/site-packages/norospy/ros.py\", line 121, in run\n",
      "    callback(decoder(payload), ts)\n",
      "  File \"/tmp/ipykernel_929149/2177829156.py\", line 13, in online_inference\n",
      "  File \"/home/ws/uqmfs/mmdetection3d/mmdet3d/apis/inferencers/base_3d_inferencer.py\", line 215, in __call__\n",
      "    results = self.postprocess(preds, visualization,\n",
      "  File \"/home/ws/uqmfs/mmdetection3d/mmdet3d/apis/inferencers/base_3d_inferencer.py\", line 273, in postprocess\n",
      "    result = self.pred2dict(pred, pred_out_dir)\n",
      "  File \"/home/ws/uqmfs/mmdetection3d/mmdet3d/apis/inferencers/base_3d_inferencer.py\", line 336, in pred2dict\n",
      "    img_path = osp.basename(data_sample.img_path)\n",
      "  File \"/home/ws/uqmfs/miniconda3/envs/openmmlab/lib/python3.8/posixpath.py\", line 142, in basename\n",
      "    p = os.fspath(p)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "INFO:root:Closing ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     client\u001b[38;5;241m.\u001b[39mrun_background()\n\u001b[1;32m      4\u001b[0m     client\u001b[38;5;241m.\u001b[39msubscribe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/carla/autopilot/front/image\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_msgs/Image\u001b[39m\u001b[38;5;124m'\u001b[39m, online_inference)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = ROSFoxgloveClient('ws://localhost:8765')\n",
    "    client.run_background()\n",
    "    client.subscribe('/carla/autopilot/front/image', 'sensor_msgs/Image', online_inference)\n",
    "    signal.pause()\n",
    "\n",
    "except NotImplementedError:\n",
    "    pass\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_destroyed_sucessfully = cam.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
